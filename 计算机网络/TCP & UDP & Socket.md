# TCP/UDP协议

:link: ​[**面试中的TCP/UDP协议**](https://blog.csdn.net/likewind1993/article/details/98382555)

:link: [TCP 重传、滑动窗口、流量控制、拥塞控制](https://mp.weixin.qq.com/s/xe3dEu17mGTqM46LRFxzhg)

UDP报文的**最大长度为512字节**

TCP允许报文长度**超过512字节**

# 重传机制

## 超时重传

重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，也就是我们常说的**超时重传**。

超时时间不同的情况：

- 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；
- 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

**超时重传时间 RTO 的值应该略大于报文往返  RTT 的值**。

> `RTT` 往返时延，也就是包的往返时间。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**

也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**

## 快速重传

当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

**重传的时候，是重传之前的一个，还是重传所有的问题。**

## SACK

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

## D-SACK

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

# 滑动窗口

**窗口大小**是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的**处理能力**来发送数据，而不会导致接收端处理不过来。

## 发送方的滑动窗口

![](https://github.com/Eleven-is-cool/img-folder/blob/master/%E5%8F%91%E9%80%81%E6%96%B9%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3.png?raw=true)

## 接受方的滑动窗口

![](https://github.com/Eleven-is-cool/img-folder/blob/master/%E6%8E%A5%E5%8F%97%E6%96%B9%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3.png?raw=true)

# 流量控制

**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

# TCP KeepAlive

长连接的环境下，进行一次数据交互后，很长一段时间内无数据交互时，客户端可能意外断电、死机、崩溃、重启，还是中间路由网络无故断开，这些**TCP连接并未来得及正常释放**，那么，连接的另一方并不知道对端的情况，它会一直维护这个连接，**长时间的积累会导致非常多的半打开连接**，造成端系统资源的消耗和浪费，且有可能导致在一个无效的数据链路层面发送业务数据，结果就是发送失败。所以**服务器端要做到快速感知失败，减少无效链接操作，这就有了TCP的Keepalive（保活探测）机制。**

# 应用层数据很大，怎么进行发送切片

[TCP分段与IP分片](https://blog.csdn.net/ns_code/article/details/30109789)

[来自知乎的一个答案](https://www.zhihu.com/question/22181709)

> 注意：因为 TCP 是在自己这一层执行分片，所以：IP层并不需要再去分片。
>
> 每个TCP分片，都是包含了完整的 TCP 协议头，这样另一方收到包之后，可以方便重组，可以计算出到底哪个分片包丢了，然后**重新传这个分片包**。
>
> 用 UDP 协议发送，那么如果网络发生了波动，丢失了某个 IP 包分片， 对于 UDP 而言， 它没有反馈丢失了哪个分片给发送方的能力，如果需要重传，就得**再次完整**的传递数据。

# 域名中的A记录和CName记录

**A记录**是用来指定主机名（或域名）对应的IP地址记录。

**CNAME记录用作别名**，相当于域名之间的映射（例如 www.baidu.com 映射到 www.a.shifen.com），而不直接与IP地址对应。

# Socket connect和accept

客户端在调用 connect 之后，将开始发起 SYN 请求，请求与服务器建立连接，此时称为第一次握手。

服务器端在接受到 SYN 请求之后，把请求方放入SYN队列中，并给客户端回复一个确认帧 ACK ，此帧还会携带一个请求与客户端建立连接的请求标志，也就是  SYN，这称为第二次握手。

客户端收到 SYN+ACK 帧后，connect 返回，并发送确认建立连接帧 ACK 给服务器端。这称为第三次握手。

服务器端收到 ACK 帧后，会把请求方从 SYN 队列中移出，放至 ACCEPT 队列中，而 accept 函数也等到了自己的资源，从阻塞中唤醒，从 ACCEPT 队列中取出请求方，重新建立一个新的 sockfd，并返回。

这里，在 connect 函数中发生了两次握手。

# 大小端

:link: [socket大小端转换](https://blog.csdn.net/guo8113/article/details/29211243?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param)

# IO模型

**Java**中，主要有三种IO模型，分别是阻塞IO（BIO）、非阻塞IO（NIO）和 异步IO（AIO）。

**Java中提供的IO有关的API，在文件处理的时候，其实依赖操作系统层面的IO操作实现的。**比如在Linux 2.6以后，Java中NIO和AIO都是通过**epoll**来实现的，而在Windows上，AIO是通过IOCP来实现的。

**同步、异步**

- **同步** ：两个同步任务相互依赖，并且一个任务必须以依赖于另一任务的某种方式执行。 比如在`A->B`事件模型中，你需要先完成 A 才能执行B。 再换句话说，同步调用中被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。
- **异步**： 两个异步的任务完全独立的，一方的执行不需要等待另外一方的执行。再换句话说，异步调用种一调用就返回结果不需要等待结果返回，当结果返回的时候通过回调函数或者其他方式拿着结果再做相关事情，

**阻塞、非阻塞**

- **阻塞：** 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。
- **非阻塞：** 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。

**如何区分 “同步/异步 ”和 “阻塞/非阻塞” 呢？**

同步/异步是从行为角度描述事物的，而阻塞和非阻塞描述的当前事物的状态（等待调用结果时的状态）。

## 同步IO

### BIO (Blocking I/O)

同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。

**单线程：**服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在`while(true)` 循环中服务端会调用 `accept()` 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成

**多线程：**接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的 **一请求一应答通信模型** 。

**总结**

在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。

### NIO (New I/O)

NIO是一种同步非阻塞的I/O模型。

NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 `Socket` 和 `ServerSocket` 相对应的 `SocketChannel` 和 `ServerSocketChannel` 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。

**BIO和NIO的区别**

1. **BIO流是阻塞的，NIO流是不阻塞的。**

   当一个线程调用 `read()` 或 `write()` 时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了

   单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到buffer中后，线程再继续处理数据。阻塞写也是如此。一个线程请求写入一些数据到某通道，但**不需要等待它完全**写入，这个线程同时可以去做别的事情。

2. **BIO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)。**

   在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的；在写入数据时，写入到缓冲区中。**任何时候访问NIO中的数据，都是通过缓冲区进行操作**。

   最常用的缓冲区是 ByteBuffer,一个 ByteBuffer 提供了一组功能用于操作 byte 数组。除了ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean类型）都对应有一种缓冲区。

   虽然**Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区**，而 NIO 却是直接读到 Buffer 中进行操作。

3. **NIO 通过Channel（通道） 进行读写。**

   通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。

4. **NIO 有选择器，而 BIO 没有。**

   选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。

## 异步IO

### AIO (Asynchronous I/O)

异步非阻塞的IO模型。异步 IO 是**基于事件和回调机制**实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。