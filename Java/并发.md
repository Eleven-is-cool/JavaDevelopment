# <span style = 'color:#45B39D'>并发</span>

## 使用多线程可能带来什么问题?

并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：**内存泄漏、死锁、线程不安全**等等。

## JDK保证线程安全的手段

线程的安全性问题体现在：

- **原子性**：一个或者多个操作在 CPU 执行的过程中不被中断的特性
- **可见性**：一个线程对共享变量的修改，另外一个线程能够立刻看到
- **有序性**：程序执行的顺序按照代码的先后顺序执行

导致原因：

- 线程切换带来的原子性问题
- 缓存导致的可见性问题
- 编译优化带来的有序性问题

解决办法：

- **JDK Atomic开头的原子类、synchronized、LOCK，可以解决原子性问题**
- **synchronized、volatile、LOCK，可以解决可见性问题**
- **Happens-Before 规则可以解决有序性问题**

## 线程状态

[Java线程的6种状态及切换(透彻讲解)](https://blog.csdn.net/pange1991/article/details/53860651)

## 线程创建

一、**继承Thread类**创建线程类

（1）定义Thread类的子类，并**重写该类的run方法**，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体。

（2）创建Thread子类的实例，即创建了线程对象。

（3）调用线程对象的start()方法来启动该线程。

二、通过**Runnable接口**创建线程类

（1）定义Runnable接口的实现类，并**重写该接口的run() **方法，该run()方法的方法体同样是该线程的线程执行体。

（2）创建 Runnable实现类的实例，并依此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。

（3）调用线程对象的start()方法来启动该线程。

三、通过**Callable和Future创建线程**

（1）创建Callable接口的实现类，并**实现call()方法**，该call()方法将作为线程执行体，**并且有返回值**。

（2）创建Callable实现类的实例，使用**FutureTask类来包装Callable对象**，该**FutureTask对象封装了该Callable对象的call()方法的返回值**。

（3）使用FutureTask对象作为Thread对象的target创建并启动新线程。

（4）调用FutureTask对象的**get()方法**来获得子线程执行结束后的返回值

## 终止线程的几种方式

- 标志位退出线程 

- stop方法强制终止

- interrupt终止线程

## 什么是上下文切换?

当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**。

## sleep() 方法和 wait() 方法区别和共同点?

- 两者最主要的区别在于：**sleep 方法没有释放锁，而 wait 方法释放了锁** 。
- 两者都可以暂停线程的执行。
- wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。
- wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 **notify()** 或者 **notifyAll()** 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。

## 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

new 一个 Thread，线程进入了新建状态；调用 start() 方法，会启动一个线程并使线程进入了**就绪状态**，**当分配到时间片后就可以开始运行了**。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。**

## Java对象头

以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（**标记字段**）、 Klass Pointer（**类型指针**）。

**Mark Word**：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。

**Klass Point**：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。

**Monitor**：Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。**每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁**。

Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。

## synchronized 关键字

synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

早期的 synchronized 属于重量级锁，效率低下，因为监视器锁( monitor )是依赖于底层的操作系统的互斥锁来实现的。挂起或者唤醒一个线程，需要操作系统切换用户态到内核态，成本较高。

synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

### 三种使用方式

- **修饰实例方法:** 作用于当前**对象实例**加锁，进入同步代码前要获得当前对象实例的锁。

- **修饰静态方法:** 也就是给**当前类**加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。

  > 如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，**因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁**。

- **修饰代码块:** 指定加锁对象，对给定类加锁，进入同步代码库前要获得给定类对象的锁。

**总结：** synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！

### 应用

[java中的单例模式](http://cool-eleven.cn/2020/03/01/java-设计模式之单例模式/)

**单例模式中的双重校验锁实现对象单例（线程安全）**

```java
// uniqueInstance 采用 volatile 关键字修饰也是很有必要的， 
// uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：

// 1. 为 uniqueInstance 分配内存空间
// 2. 初始化 uniqueInstance
// 3. 将 uniqueInstance 指向分配的内存地址

// 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在
// 单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。
// 例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，
// 因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。
// 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。
public class Singleton {
    private volatile static Singleton uniqueInstance;
    private Singleton() {
    }
    public static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
```

### 底层原理

**① synchronized 同步语句块的情况**

```java
public class SynchronizedDemo {
	public void method() {
		synchronized (this) {
			System.out.println("synchronized 代码块");
		}
	}
}
```

**synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。** 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(**monitor对象存在于每个Java对象的对象头中，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁**，这种依赖于操作系统Mutex Lock所实现的锁我们称之为“**重量级锁**”）来实现的线程同步，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

**② synchronized 修饰方法的的情况**

```java
public class SynchronizedDemo2 {
	public synchronized void method() {
		System.out.println("synchronized 方法");
	}
}
```

synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

### synchronized 与 Lock 的区别

1. Lock是java的一个interface接口，而synchronized是Java中的关键字

2. synchronized修饰的代码在执行异常时，**jdk会自动释放线程占有的锁**，不需要程序员去控制释放锁，因此不会导致死锁现象发生；但是，当Lock发生异常时，如果程序没有通过**unLock()**去释放锁，则很可能造成死锁现象，因此Lock一般都是在**finally块**中释放锁；

3. Lock可以让等待锁的线程响应中断处理，synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够中断，程序员无法控制；

4. Lock锁的范围有局限性，仅适用于代码块范围，而synchronized可以锁住代码块、对象实例、类；

## 锁机制

:icecream: 来自美团技术团队的文章：[不可不说的Java“锁”事](https://tech.meituan.com/2018/11/15/java-lock.html)

![lockfrommeituan.png](https://github.com/Eleven-is-cool/img-folder/blob/master/lockfrommeituan.png?raw=true)

### 乐观锁 VS 悲观锁

**悲观锁：**对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，**synchronized**关键字和**Lock**的实现类都是悲观锁。

**乐观锁：**在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。乐观锁在Java中是通过使用无锁编程来实现，最常采用的是**CAS算法**，Java原子类中的递增操作就通过CAS自旋实现的。

CAS虽然很高效，但是它也存在三大问题，这里也简单说一下：

1. **ABA问题**

   CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。

   - JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。

2. **循环时间长开销大**。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。

3. **只能保证一个共享变量的原子操作**

   对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。

   - Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。

- **悲观锁适合写操作多**的场景，先加锁可以保证写操作时数据正确。
- **乐观锁适合读操作多**的场景，不加锁的特点能够使其读操作的性能大幅提升。

### 自旋锁 VS 适应性自旋锁

阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，**状态转换消耗的时间有可能比用户代码执行的时间还要长。**

在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。

而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。

<img src="https://github.com/Eleven-is-cool/img-folder/blob/master/zixuansuofrommeituan.png?raw=true" style="zoom: 50%;" />

**缺点**：如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。

- 自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。

自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/83b3f85e.png)

**适应性自旋锁**

JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。

自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。

### 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁

这四种锁是指锁的状态，专门针对synchronized的。

在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是**synchronized最初实现同步**的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“**重量级锁**”，**JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。**

所以目前锁一共有4种状态，级别从低到高依次是：**无锁、偏向锁、轻量级锁和重量级锁**。锁状态只能升级不能降级。

**四种锁状态对应的的Mark Word内容**

| 锁状态   | 存储内容                                                | 存储内容 |
| :------- | :------------------------------------------------------ | :------- |
| 无锁     | 对象的hashCode、对象分代年龄、是否是偏向锁（0）         | 01       |
| 偏向锁   | 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） | 01       |
| 轻量级锁 | 指向栈中锁记录的指针                                    | 00       |
| 重量级锁 | 指向互斥量（重量级锁）的指针                            | 10       |

**无锁**

CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。

**偏向锁**

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。

当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是**检测Mark Word里是否存储着指向当前线程的偏向锁**。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而**偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可**。

偏向锁只有遇到其他线程尝试竞争偏向锁时，**持有偏向锁的线程才会释放锁**，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。

偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。

**偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作**

**轻量级锁**

是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。

在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。

拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。

如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。

如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。

若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。

**轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。**

**重量级锁**

升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。

**重量级锁是将除了拥有锁的线程以外的线程都阻塞。**

### 公平锁 VS 非公平锁

公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。

> 优点：等待锁的线程不会饿死。
>
> 缺点：整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。

非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。

> 优点：可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。
>
> 缺点：处于等待队列中的线程可能会饿死，或者等很久才会获得锁。

**综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。**

**公平锁和非公平锁只有两处不同：**

1. 非公平锁在**调用 lock** 后，首先就会**调用 CAS 进行一次抢锁**，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。
2. 非公平锁在 CAS 失败后，和公平锁一样都会进入到 **tryAcquire** 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），**非公平锁会直接 CAS 抢锁**，但是**公平锁会判断等待队列是否有线程处于等待状态**，如果有则不去抢锁，乖乖排到后面。

公平锁和非公平锁就这两点区别，**如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。**

### 可重入锁 VS 非可重入锁

**可重入锁：**是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中**ReentrantLock**和**synchronized**都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。

**为什么非可重入锁在重复调用同步资源时会出现死锁？**

首先**ReentrantLock**和**NonReentrantLock**都继承父类**AQS**，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。

当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。

释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。

### 独享锁 VS 共享锁

**独享锁也叫排他锁**，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。

**共享锁**是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。

独享锁与共享锁也是通过**AQS**来实现的，通过实现不同的方法，来实现独享或者共享。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/762a042b.png)



- ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。
- ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。
- 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。

## synchronized和ReentrantLock 的区别

**① 两者都是可重入锁**

**② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**

synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。

**③ ReentrantLock 比 synchronized 增加了一些高级功能**

主要来说主要有三点：**1.等待可中断；2.可实现公平锁；3.可实现选择性通知（锁可以绑定多个条件）**

- **ReentrantLock提供了一种能够中断等待锁的线程的机制**，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
- **ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。** ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。
- synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），**线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”** ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。

如果你想使用上述功能，那么选择ReentrantLock是一个不错的选择。

**④ 性能已不是选择标准**

## volatile关键字

[https://www.jianshu.com/p/157279e6efdb](https://www.jianshu.com/p/157279e6efdb)

在生成汇编代码时会在volatile修饰的共享变量进行写操作的时候会多出**Lock前缀的指令**。这个**Lock**指令主要有这两个方面的影响：

1. **将当前处理器缓存行的数据写回系统内存；**
2. **这个写回内存的操作会使得其他CPU里缓存了该内存地址的数据无效**

多个线程并发读写一个共享变量的时候，有可能**某个线程修改了变量的值，但是其他线程看不到**！ 而加上volatile来修饰变量时，每次对该变量的修改，都会**强制将变量的新值刷回主存**。同时让别的线程的工作内存的**该变量直接失效**。

volatile本质是在告诉jvm当前变量在工作内存中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。

**volatile** 关键字的主要作用就是保证变量的可见性然后还有一个作用是**防止指令重排序**。

## 内存屏障

为了性能优化，JMM在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序，那如果想阻止重排序要怎么办了？答案是可以**添加内存屏障**。

## happens-before

[Java内存模型以及happens-before规则](https://juejin.im/post/6844903600318054413)

**JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证**

1）如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且**第一个操作的执行顺序排在第二个操作之前**。

2）两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。**如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法**（也就是说，JMM允许这种重排序）。

## as-if-serial   VS   happens-before

1. **as-if-serial**语义**保证单线程内程序的执行结果不被改变**，happens-before关系**保证正确同步的多线程程序的执行结果不被改变**。
2. as-if-serial语义给编写单线程程序的程序员创造了一个幻境：**单线程程序是按程序的顺序来执行的**。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：**正确同步的多线程程序是按happens-before指定的顺序来执行的**。
3. as-if-serial语义和happens-before这么做的目的，都是为了**在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。**

## 并发编程的三个重要特性

1. **原子性** : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。`synchronized `可以保证代码片段的原子性。
2. **可见性** ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。`volatile` 关键字可以保证共享变量的可见性。
3. **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。`volatile` 关键字可以禁止指令进行重排序优化。

## synchronized 关键字和 volatile 关键字的区别

1. **volatile关键字**是线程同步的**轻量级实现**
2. **volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块**
3. **多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞**
4. **volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。**
5. **volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。**

## ThreadLocal

**`ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。**

如果你创建了一个`ThreadLocal`变量，那么**访问这个变量的每个线程都会有这个变量的本地副本**，这也是`ThreadLocal`变量名的由来。他们可以使用 **`get（）` 和 `set（）` 方法来获取默认值或将其值更改为当前线程所存的副本的值**，从而避免了线程安全问题。

每个`Thread`中都具备**一个`ThreadLocalMap`**，而`ThreadLocalMap`可以存储**以`ThreadLocal`为key ，Object 对象为 value的键值对**。

> 比如我们在同一个线程中声明了两个 `ThreadLocal` 对象的话，会使用 `Thread`内部都是使用仅有那个`ThreadLocalMap` 存放数据的，`ThreadLocalMap`的 key 就是 `ThreadLocal`对象，value 就是 `ThreadLocal` 对象调用`set`方法设置的值。`ThreadLocalMap`是`ThreadLocal`的静态内部类。

## ThreadLocal 内存泄露问题

**`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用,而 value 是强引用**。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法

## 为什么要用线程池

[面试必备：Java线程池解析](https://juejin.im/post/6844903889678893063)

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

## 执行execute()方法和submit()方法的区别是什么

1. **`execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**
2. **`submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功**，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get（long timeout，TimeUnit unit）`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

## 如何创建线程池

通过 **ThreadPoolExecutor** 的方式

> Executors 返回线程池对象的弊端如下：
>
> - **FixedThreadPool 和 SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。
> - **CachedThreadPool 和 ScheduledThreadPool** ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。

**方式一：通过构造方法实现** [![ThreadPoolExecutor构造方法](https://camo.githubusercontent.com/c1a87ea139bc0379f5c98484416594843ff29d6d/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f546872656164506f6f6c4578656375746f722545362539452538342545392538302541302545362539362542392545362542332539352e706e67)](https://camo.githubusercontent.com/c1a87ea139bc0379f5c98484416594843ff29d6d/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f546872656164506f6f6c4578656375746f722545362539452538342545392538302541302545362539362542392545362542332539352e706e67) **方式二：通过Executor 框架的工具类Executors来实现**，我们可以创建三种类型的ThreadPoolExecutor：

- **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
- **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
- **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。

对应Executors工具类中的方法如图所示： [![Executor框架的工具类](https://camo.githubusercontent.com/6cfe663a5033e0f4adcfa148e6c54cdbb97c00bb/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f4578656375746f722545362541312538362545362539452542362545372539412538342545352542372541352545352538352542372545372542312542422e706e67)](https://camo.githubusercontent.com/6cfe663a5033e0f4adcfa148e6c54cdbb97c00bb/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f4578656375746f722545362541312538362545362539452542362545372539412538342545352542372541352545352538352542372545372542312542422e706e67)

## `ThreadPoolExecutor`构造函数重要参数

**`ThreadPoolExecutor` 3 个最重要的参数：**

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

`ThreadPoolExecutor`其他常见参数:

1. **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. **`unit`** : `keepAliveTime` 参数的时间单位。
3. **`threadFactory`** :executor 创建新线程的时候会用到。
4. **`handler`** :饱和策略。

## `ThreadPoolExecutor` 饱和策略

**`ThreadPoolExecutor` 饱和策略定义:**

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，`ThreadPoolTaskExecutor` 定义一些策略:

- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。**即不用线程池中的线程执行，而是交给调用方来执行。**
- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。
- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。

## `ThreadPoolExecutor` 增长策略

默认情况下，**初始时线程池是空的**，当有新任务来了时，**线程池开始通过线程工厂(threadFractory)创建线程来处理任务**。

新的任务会不断的触发线程池中线程的创建，直到线程数量达到**核心线程数**(corePoolSize)，接下来会停止线程的创建，而是将这个**新任务放入任务等待队列**(workQueue)。

**新任务不断进入任务等待队列，当该队列满了时，开始重新创建线程处理任务，直到线程池中线程的数量，到达 maximumPoolSize 配置的数量。**

到这一步时，线程池的线程数达到最大值，并且没有空闲的线程，任务队列也存满了任务，这时如果还有新的任务进来，就会触发线程池的拒绝策略(handler)，如果没有配置拒绝策略就会抛出 RejectedExecutionException 异常。

## Atomic 原子类

[Atomic 原子类](https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/Atomic.md#1-atomic-%E5%8E%9F%E5%AD%90%E7%B1%BB%E4%BB%8B%E7%BB%8D)

Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

AtomicInteger 类主要利用 **CAS (compare and swap) + volatile 和 native** 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

## AQS 原理

**AQS**核心思想：如果被请求的共享资源**空闲**，则将当前**请求资源的线程设置为有效的工作线程**，并且将共享资源设置为**锁定**状态。如果被请求的共享资源**被占用**，那么就需要**一套线程阻塞等待以及被唤醒时锁分配的机制**，这个机制AQS是用CLH队列锁实现的，即**将暂时获取不到锁的线程加入到队列中**。

![image](https://github.com/Eleven-is-cool/img-folder/blob/master/AQS.png?raw=true)

## `sleep() 、join（）、wait()、yield（）`有什么区别

`sleep()`在指定的毫秒数内让当前正在执行的线程休眠（暂停执行）。`sleep()`可以使用低优先级的线程得到执行的机会，当然也可以让同优先级的线程有执行的机会，sleep 是 Thread 类的静态本地方法。

`wait` 方法让获得对象锁的线程实现等待，多用于多线程之间的通信，需要额外的方法 `notify/ notifyAll` 进行唤醒，放在 synchronized 块里面，同样需要捕获 InterruptedException 异常，wait 则是 Object 类的本地方法。

Thread的非静态方法`join()`让一个线程B“加入”到另一个线程A的尾部，在A执行完毕之前，B不能工作。

`yield()`方法只是**使当前线程重新回到可执行状态**，所以执行`yield()`的线程有可能在进入到可执行状态后，马上又被执行，另外yield()方法只能使用同优先级或者高优先级的线程得到执行机会，这也和sleep()方法不同。

## AQS 组件

- **Semaphore(信号量)-允许多个线程同时访问**
- **CountDownLatch （倒计时器）**
- **CyclicBarrier(循环栅栏)**

### 说说 Semaphore 原理

Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，保证合理的使用公共资源。

线程可以通过`acquire()`方法来**获取**信号量的许可，当信号量中没有可用的许可的时候，线程阻塞，直到有可用的许可为止。线程可以通过`release()`方法**释放**它持有的信号量的许可。

> **synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。**

Semaphore 有两种模式，公平模式和非公平模式。

- **公平模式：** 调用acquire的顺序就是获取许可证的顺序，遵循FIFO；
- **非公平模式：** 抢占式的。

### 说说CountDownLatch（倒计时器）原理

在多线程并发编程中充当一个计时器的功能, CountDownLatch也是一个java.util.concurrent包中的类，**可以设置一个初始数值，在数值大于0之前让调用await()方法的线程堵塞住，数值为0是则会放开所有阻塞住的线程。**

**典型用法：**

①**某一线程在开始运行前等待n个线程执行完毕**。将 CountDownLatch 的计数器初始化为n ：`new CountDownLatch(n)`，每当一个任务线程执行完毕，就将计数器减1 `countdownlatch.countDown()`，当计数器的值变为0时，在`CountDownLatch上 await()` 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。

②实现多个线程开始执行任务的**最大并行性**。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 `CountDownLatch` 对象，将其计数器初始化为 1 ：`new CountDownLatch(1)`，**多个线程在开始执行任务前首先 `coundownlatch.await()`，当主线程调用 countDown() 时，计数器变为0，多个线程同时被唤醒**。

**缺点：**CountDownLatch是**一次性**的，**计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，**当CountDownLatch使用完毕后，它不能再次被使用。

### 说说 CyclicBarrier（循环栅栏） 原理

在CyclicBarrier类的内部有一个计数器，每个线程在到达屏障点的时候都会调用await方法将自己阻塞，此时计数器会加1，**当计数器加到一个数的时候所有因调用await方法而被阻塞的线程将被唤醒。**

**CyclicBarrier的计数器提供reset功能，可以多次使用**。

### 说说 CountDownLatch 与 CyclicBarrier 区别

CountDownLatch 减法，为0时，线程运行，归0后不能重置，一个线程等其他线程都执行完他才执行。

CyclicBarrier 加法，到达一个值，线程运行，到达值后变为0，继续用，几个线程相互等待，一起执行。

> **CountDownLatch 是等待一组线程执行完，才执行后面的代码。此时这组线程已经执行完。**
> **CyclicBarrier 是等待一组线程至某个状态后再同时全部继续执行线程。此时这组线程还未执行完。**

## Exchanger 原理

两个线程到了一个同步点才能互相交换数据。

## 并发容器之BlockingQueue

:link: [https://juejin.im/post/6844903602444582920](https://juejin.im/post/6844903602444582920)

:link: [https://blog.csdn.net/pange1991/article/details/80930394](https://blog.csdn.net/pange1991/article/details/80930394)