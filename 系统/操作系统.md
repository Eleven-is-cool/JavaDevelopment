# 操作系统概念

1. 操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机的基石。
2. 操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。
3. 操作系统存在屏蔽了硬件层的复杂性。 操作系统就像是硬件使用的负责人，统筹着各种相关事项。
4. 操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

# 基本功能

## 1. 进程管理

进程控制、进程同步、进程通信、死锁处理、处理机调度等。

## 2. 内存管理

内存分配、地址映射、内存保护与共享、虚拟内存等。

## 3. 文件管理

文件存储空间的管理、目录管理、文件读写管理和保护等。

## 4. 硬件设备管理

完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。

主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

# 系统调用

在我们运行的用户程序中，凡是与**系统态级别的资源有关的操作**（如文件管理、进程控制、内存管理等)，都必须通过**系统调用**方式向操作系统提出**服务请求**，并由操作系统代为完成。

Linux 的系统调用主要有以下这些：

| Task     | Commands                    |
| -------- | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
| 安全     | chmod(); umask(); chown();  |

# 大内核和微内核

## 1. 大内核

大内核是将操作系统功能作为一个紧密结合的整体放到内核。

由于各模块共享信息，因此有很高的性能。

## 2. 微内核

由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。

在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。

因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。

# 中断分类

## 1. 外中断

由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

## 2. 异常

由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

## 3. 陷入

在用户程序中使用系统调用。

# 进程与线程

## 1. 进程

进程是操作系统进行资源分配和调度的基本单元。

进程是操作系统中执行的一个程序，操作系统以进程为单位分配存储空间，每个进程都有自己的地址空间、数据栈以及其他用于跟踪进程执行的辅助数据。

进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。

## 2. 线程

线程只是CPU调度和分派的基本单位。

一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

## 3. 区别

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

Ⅱ 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

**进程有独立的地址空间，线程共享进程的地址空间。**

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

# 并发与并行

**并发：**在一个**时间段**中多个程序都启动运行在同一个处理机中

**并行：**假设目前A，B两个进程，两个进程分别由不同的 CPU  管理执行，两个进程不抢占 CPU  资源且可以**同时运行**，这叫做并行。

# 内存管理机制

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。

1. **块式管理** ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式管理机制**：段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。

# 分页与分段

### 分页机制和分段机制的共同点和区别

1. 共同点
   - 分页机制和分段机制**都是为了提高内存利用率，较少内存碎片。**
   - 页和段都是离散存储的，所以两者都是**离散分配内存**的方式。但是，每个页和段中的内存是连续的。
2. 区别
   - **页的大小是固定的**，由操作系统决定；**而段的大小不固定**，取决于我们当前运行的程序。
   - **分页仅仅是为了满足操作系统内存管理的需求，**而段是逻辑信息的单位，**在程序中可以体现为代码段，数据段，能够更好满足用户的需要**。

虚拟地址是怎么转换为物理地址的呢？

第一种方式，采用一个映射表代表虚拟地址到物理地址的映射，在计算机中我们叫做**页表**。页表将内存地址分为**页号**和**偏移量**，举个例子

我们将高位部分称为内存地址的页号，后面的低位叫做**内存地址的偏移量**。我们只需要保存虚拟地址内存的页号和物理内存页号之间的映射关系即可。

![在这里插入图片描述](https://mmbiz.qpic.cn/mmbiz_png/NdsdouZwicaeY0fdOUxrwTABu5sAN6O6uZg8rticAPFUxVvK25YyiaDq0tGZR0IPc470heMdaFRDz4Jc8nJRAtVRg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

   - 虚拟地址-----> 页号+偏移量

   - 通过页表查询出虚拟页号，对应的物理页号

   - 物理页号+偏移量-----> 物理内存地址

第二种方法，多级页表

![二级索引](https://mmbiz.qpic.cn/mmbiz_png/NdsdouZwicaeY0fdOUxrwTABu5sAN6O6u1uUDJ3mP1kbO3ZcxibYicRZ4kibC6sErt2Jx9TTRZQcLZfM6JI1yxemHw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

# 快表和多级页表

#### 快表

快表和多级页表解决了页表管理中很重要的两个问题。

1. 虚拟地址到物理地址的转换要快。
2. 解决虚拟地址空间大，页表也会很大的问题。

可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。**作为页表的 Cache**，它的作用与页表相似，**但是提高了访问速率**。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，**这样可加速查找并提高指令执行速度。**

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

#### 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。



# IPC进程间通信

> [《进程间通信 IPC (InterProcess Communication)》](https://www.jianshu.com/p/c1015f5ffa74) 

1. **管道/匿名管道(Pipes)** ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。

   创建命名管道的方式

   > mkfifo test

   test即为管道的名称，在Linux中一切皆文件，管道也是以文件的方式存在，咋们可以使用ls -l 查看下文件的属性，它会"p"标识。

   ![img](https://mmbiz.qpic.cn/mmbiz_png/NdsdouZwicaeY0fdOUxrwTABu5sAN6O6uuOBI3kVicnFR2Uoq0g4SMKkOXticG8B1b1cA4a0KCPdljZV0qIEQs2hg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

   下面我们向管道写入内容

   > echo "666" > test

   ![img](https://mmbiz.qpic.cn/mmbiz_png/NdsdouZwicaeY0fdOUxrwTABu5sAN6O6u1MyiaDM5JibrDiaS1xEuvWpOLRAsz41cNfiam1WZKEQxOFPricI9jZ2clnw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

   此时按道理来说咱们已经将内容写入了test，没有直接输出是因为我们需要开启另一个终端进行输出(可以理解为暂存管道)

   > cat < test

   管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

   ```c
   #include <unistd.h>
   int pipe(int fd[2]);
   ```

   它具有以下限制：

   - 只支持半双工通信（单向交替传输）；
   - 只能在父子进程或者兄弟进程中使用。

   [![img](https://camo.githubusercontent.com/ea23bf43dfe705c9b9c1016389993e609b50a1ee/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35336364396164652d623061362d343339392d623464652d3766316662643036636466622e706e67)](https://camo.githubusercontent.com/ea23bf43dfe705c9b9c1016389993e609b50a1ee/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35336364396164652d623061362d343339392d623464652d3766316662643036636466622e706e67)

2. **有名管道(Names Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循**先进先出(first in first out)**。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

3. **信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；

4. **消息队列(Message Queuing)** ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺。**

5. **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。

6. **共享内存(Shared memory)** ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。

7. **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

# 进程状态的切换

![img](https://camo.githubusercontent.com/99816e8c9d2d59b711ec4134f6200857074596e4/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f50726f6365737353746174652e706e67)

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

# 线程间的同步

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。

2. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量

   > 信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。
   >
   > - **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
   > - **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。
   >
   > down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。
   >
   > 如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

   **使用信号量实现生产者-消费者问题**

   问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

   因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

   为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

   注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

   ```c
   #define N 100
   typedef int semaphore;
   semaphore mutex = 1;
   semaphore empty = N;
   semaphore full = 0;
   
   void producer() {
       while(TRUE) {
           int item = produce_item();
           down(&empty);
           down(&mutex);
           insert_item(item);
           up(&mutex);
           up(&full);
       }
   }
   
   void consumer() {
       while(TRUE) {
           down(&full);
           down(&mutex);
           int item = remove_item();
           consume_item(item);
           up(&mutex);
           up(&empty);
       }
   }
   ```

3. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操

4. **临界值**：让多线程串行话去访问资源

# 哲学家进餐问题

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

```c
#define N 5

void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       // 拿起左边的筷子
        take((i+1)%N); // 拿起右边的筷子
        eat();
        put(i);
        put((i+1)%N);
    }
}
```

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```c
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```

# 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```c
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

# 进程的调度算法

## 1. 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

## 2. 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转**

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

![img](https://camo.githubusercontent.com/8ff909218be7e1269ee5912f0aba9fcb3552df3b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38633636323939392d633136632d343831632d396634302d3166646261356263393136372e706e67)

**2.2 优先级调度**

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列**

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

[![img](https://camo.githubusercontent.com/a69a61aafa8f82822c3679b989d58d1ce332f9ae/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30343263663932382d336338652d343831352d616539632d6632373830323032633638662e706e67)](https://camo.githubusercontent.com/a69a61aafa8f82822c3679b989d58d1ce332f9ae/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30343263663932382d336338652d343831352d616539632d6632373830323032633638662e706e67)

## 3. 实时系统

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

# 死锁

## 危害

[进程死锁的危害、导致原因、解决方法](https://blog.csdn.net/dqjyong/article/details/8046397)

## 必要条件

- 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

## 处理方法

### 鸵鸟策略

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

### 死锁检测与死锁恢复

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

### 死锁预防

在程序运行之前预防发生死锁。

1. **破坏互斥条件**

   例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

2. **破坏占有和等待条件**

   一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

3. **破坏不可抢占条件**

4. **破坏环路等待**

   给资源统一编号，进程只能按编号顺序来请求资源。

### 死锁避免

在程序运行时避免发生死锁。

1. **安全状态**

   如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

2. **单个资源的银行家算法**

   一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

   [![img](https://camo.githubusercontent.com/2e063f0d8171d2ee77e56000d223ec3030bbca38/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64313630656332652d636665322d343634302d626461372d3632663533653538623863302e706e67)](https://camo.githubusercontent.com/2e063f0d8171d2ee77e56000d223ec3030bbca38/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64313630656332652d636665322d343634302d626461372d3632663533653538623863302e706e67)

   

   上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。

3. **多个资源的银行家算法**

   ![img](https://camo.githubusercontent.com/91b6f9c03034b15dcfef7b7155255ca8a27f5a5b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36326530646434662d343463332d343365652d626236652d6665646239653036383531392e706e67)

   上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

   检查一个状态是否安全的算法如下：

   - 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
   - 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
   - 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

   如果一个状态不是安全的，需要拒绝进入这个状态。

# 同步、异步、阻塞、非阻塞

**同步**：当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。

**异步**：当一个异步过程调用发出后，调用者不能立刻得到返回结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。

**阻塞**：是指调用结果返回前，当前线程会被挂起，即阻塞。

**非阻塞**：是指即使调用结果没返回，也不会阻塞当前线程。

# IO模型

## 阻塞IO模型

阻塞 I/O 是最简单的 I/O 模型，一般表现为进程或线程等待某个条件，如果条件不满足，则一直等下去。条件满足，则进行下一步操作。

应用进程通过系统调用 `recvfrom` 接收数据，但由于内核还未准备好数据报，应用进程就会阻塞住，直到内核准备好数据报，`recvfrom` 完成数据报复制工作，应用进程才能结束阻塞状态。

![](https://raw.githubusercontent.com/Eleven-is-cool/img-folder/master/NIO.webp)

## 非阻塞IO模型

应用进程与内核交互，目的未达到之前，不再一味的等着，而是直接返回。然后通过轮询的方式，不停的去问内核数据准备有没有准备好。如果某一次轮询发现数据已经准备好了，那就把数据拷贝到用户空间中。

应用进程通过 `recvfrom` 调用不停的去和内核交互，直到内核准备好数据。如果没有准备好，内核会返回`error`，应用进程在得到`error`后，过一段时间再发送`recvfrom`请求。在两次发送请求的时间段，进程可以先做别的事情。

![](https://raw.githubusercontent.com/Eleven-is-cool/img-folder/master/BIO.webp)

## 信号驱动IO模型

应用进程在读取文件时通知内核，**如果某个 socket 的某个事件发生时，请向我发一个信号**。在收到信号后，信号对应的处理函数会进行后续处理。

应用进程预先向内核注册一个信号处理函数，然后用户进程返回，并且不阻塞，当内核数据准备就绪时会发送一个信号给进程，用户进程便在信号处理函数中开始把数据拷贝的用户空间中。

![](https://raw.githubusercontent.com/Eleven-is-cool/img-folder/master/signalNIO.webp)

## IO复用模型

多个进程的IO可以注册到同一个管道上，这个管道会统一和内核进行交互。当管道中的某一个请求需要的数据准备好之后，进程再把对应的数据拷贝到用户空间中。本质上select/poll/epoll都是同步I/O，即读写是阻塞的。

**IO多路复用机制，可以同时监控多个描述符，当某个描述符就绪(读或写就绪)，则立刻通知相应程序进行读或写操作。**

select、poll、epoll模型。在IO多路复用的时候，process在两个处理阶段都是block住等待的。初看好像IO多路复用没什么用，其实**select、poll、epoll**的优势在于可以以较少的代价来同时监听处理多个IO。

![](https://raw.githubusercontent.com/Eleven-is-cool/img-folder/master/IO%E5%A4%8D%E7%94%A8.webp)

**IO多路复用的三种实现方式**

- select
- poll
- epoll

### select

- 单个进程能够监视的文件描述符的数量存在最大限制，通常是1024，当然可以更改数量
- 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大（内核/用户空间内存拷贝问题，select需要复制大量的句柄数据结构，产生巨大的开销；）
- 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）

### poll

- pollfd结构包含了要监视的event和发生的event，并且pollfd并没有最大数量限制。和select函数一样，当poll函数返回后，可以**通过遍历描述符集合，找到就绪的描述符**。

- 每次调用poll，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
- 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）

### epoll

- epoll **使用一个文件描述符管理多个描述符**，将用户空间的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的 copy 只需一次。
- **epoll 应用**
  - **redis**
  - **nginx**

有100万个客户端同时与一个服务器进程保持着TCP连接。而每一时刻，通常只有几百上千个 TCP 连接是活跃的。如何实现这样的高并发？

在 select/poll 时代，服务器进程每次都把这100万个连接告诉操作系统（从用户态复制句柄数据结构到内核态），**让操作系统内核去查询这些套接字上是否有事件发生**，**轮询完后，再将句柄数据复制到用户态**，**让服务器应用程序轮询处理已发生的网络事件**，这一过程资源消耗较大，因此，select/poll 一般只能处理几千的并发连接。

select/poll 都只有一个方法，epoll操作过程有3个方法，分别是 `epoll_create()`， `epoll_ctl()`，`epoll_wait()`。epoll 的设计和实现 select 完全不同。epoll 通过在 linux 内核中申请一个简易的文件系统（文件系统一般用什么数据结构实现？B+树）。把原先的 select/poll 调用分成了3个部分：

**1）调用 `epoll_create()` 建立一个 epoll 对象（在 epoll 文件系统中为这个句柄对象分配资源）**

**2）调用 `epoll_ctl` 向 epoll 对象中添加这100万个连接的套接字**

**3）调用 `epoll_wait` 收集发生的事件的连接**

首先要调用 `epoll_create` 创建一个 epoll 对象。然后使用 `epoll_ctl` 可以操作上面建立的epoll对象，例如，将刚建立的 socket 加入到 epoll 中让其监控，或者把 epoll 正在监控的某个 socket 句柄移出 epoll，不再监控它等等。`epoll_wait` 在调用时，在给定的 timeout 时间内，当在监控的所有句柄中有事件发生时，就返回用户态的进程。

在 select/poll 中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过 epoll_ctl() 来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似 callback 的回调机制，迅速激活这个文件描述符，当进程调用 epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是 epoll 的魅力所在。)

**epoll优势**

1. 监视的描述符数量不受限制，所支持的FD上限是最大可以打开文件的数目，具体数目可以`cat /proc/sys/fs/file-max`查看，一般来说这个数目和系统内存关系很大，以3G的手机来说这个值为20-30万。
2. IO性能不会随着监视fd的数量增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的，只有就绪的fd才会执行回调函数。

如果没有大量的空闲或者死亡连接，epoll的效率并不会比select/poll高很多。但当遇到大量的空闲连接的场景下，epoll的效率大大高于select/poll。

**epoll的两种触发方式**

**Level_triggered(水平触发)：**当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上次没读写完的文件描述符上继续读写

**Edge_triggered(边缘触发)：**当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你

> 水平触发时如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率，而边缘触发，则不会充斥大量你不关心的就绪文件描述符，从而性能差异，

|                            | select             | poll             | epoll                                             |
| :------------------------- | :----------------- | :--------------- | :------------------------------------------------ |
| 数据结构                   | 数组               | 链表             | 红黑树                                            |
| 能够监控的文件描述符的数量 | 1024               | 无上限           | 无上限                                            |
| fd拷贝                     | 每次调用select拷贝 | 每次调用poll拷贝 | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 工作效率                   | 轮询：O(n)         | 轮询：O(n)       | 回调：O(1)                                        |

## 异步IO模型

应用进程把IO请求传给内核后，完全由内核去操作文件拷贝。内核完成相关操作后，会发信号告诉应用进程本次IO已经完成。

![](https://raw.githubusercontent.com/Eleven-is-cool/img-folder/master/%E5%BC%82%E6%AD%A5IO.webp)

# 多线程与多进程的应用场景

**多线程的优点**

- 更加高效的内存共享。多进程下内存共享不便
- 较轻的上下文切换。因为不用切换地址空间，CR3寄存器和清空TLB

**多进程的优点：**

- 各个进程有自己内存空间，所以具有更强的容错性，不至于一个集成crash导致系统崩溃
- 具有更好的多核可伸缩性，因为进程将地址空间，页表等进行了隔离，在多核的系统上可伸缩性更强

**如何提升多线程的效率**

- 尽量使用池化技术，也就是线程池，从而不用频繁的创建，销毁线程
- 减少线程之间的同步和通信
- 通过Huge Page的方式避免产生大量的缺页异常
- 避免需要频繁共享写的数据

# 可中断的睡眠状态和不可中断的状态

TASK_UNINTERRUPTIBLE 状态，主要是因为**内核中的进程不是什么进程都可以被打断**，假设响应的是**异步信号**，程序在执行的过程中插入一段用于处理异步信号的而流程，原来的流程就会被中断。所以当进程在和硬件打交道的时候，需要使用 TASK_UNINTERRUPTIBLE 状态将进程保护起来，从而避免进程和设备打交道的过程中被打断导致设备处于不可控的状态。

正常情况，TASK_UNINTERRUPTIBLE状态存在时间很短，但是不排除存在此状态进程比较持久的情况。内核提供了**hung task**机制，它会启动一个khungtaskd内核线程对TASK_UNINTERRUPTIBLE状态进行检测，不能让他失控了。khungtaskd会定期的唤醒，如果超过120s都还没有调度，内核就会通过打印警告和堆栈信息。

# 如何查看进程或者端口是否在使用

```shell
netstat -nlp | grep XXX
```

这里的"|"实际上就是管道的意思。"|"前面部分作为"|"后面的输入，很明显是**单向的传输**，这样的管道我们叫做**"匿名管道"**，自行创建和销毁。既然有匿名管道，应该就有带名字的管道"命名管道"。如果你想双向传输，可以考虑使用两个管道拼接即可。

# CPU 寻址了解吗?为什么需要虚拟地址空间?

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。如下图所示：

[![MMU_principle_updated](https://camo.githubusercontent.com/9ed9e98c2f76ad474a9cac651f455b6b64e2ffd1/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d31312f32623237646163386363363437663861616339383964613264313136366462322e706e67)](https://camo.githubusercontent.com/9ed9e98c2f76ad474a9cac651f455b6b64e2ffd1/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d31312f32623237646163386363363437663861616339383964613264313136366462322e706e67)

**为什么要有虚拟地址空间呢？**

先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存** 。但是这样有什么问题呢？

1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。
2. 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列**相邻的虚拟地址**来**访问**物理内存中**不相邻**的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，**内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动**。
- **不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。**

# 虚拟内存

这个在我们平时使用电脑特别是 Windows 系统的时候太常见了。很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。**为什么可以这样呢？** 正是因为 **虚拟内存** 的存在，通过 **虚拟内存** 可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。

**虚拟内存**是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**。

## 局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。

## 虚拟存储器

基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——**虚拟存储器**。

## 虚拟内存的技术实现

**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。** 虚拟内存的实现有以下三种方式：

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

不管是上面那种实现方式，我们一般都需要：

1. 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换。

## **请求分页与分页存储管理，两者有何不同呢？**

请求分页存储管理建立在分页管理之上。他们的根本区别是**是否将程序全部所需的全部地址空间都装入主存，**这也是请求分页存储管理可以提供虚拟内存的原因，我们在上面已经分析过了。

**它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。**请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，**请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。**

# 页面置换算法

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Currently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。

# 计算机系统中缓冲

为了**缓和CPU和外设之间的矛盾**，操作系统引入了**单缓冲、双缓冲以及循环缓冲**。

所有单缓冲，就是在CPU和外设之间设置了一个缓冲区，当有数据交换时，先把数据发往缓冲区，再从缓冲区中读取数据。

双缓冲就是具有两个缓冲，当一个进程正在往一个缓冲区读数据的时候，操作系统可能正在读或写另外一个缓冲区。

循环缓冲区就是具有多个缓冲区的组合，它更加能够缓和CPU和外设之间速度的不匹配。

## 冯诺依曼结构的五个主要组成部分

- 运算器
- 控制器
- 存储器
- 输入设备
- 输出设备

https://zhuanlan.zhihu.com/p/136748306

# 零拷贝

:link: ​[总结来源](https://mp.weixin.qq.com/s/Ps0XnqgH8KPBgmfEB5qzVA)

![传统io](https://github.com/Eleven-is-cool/img-folder/blob/master/%E4%BC%A0%E7%BB%9FIO%E6%B5%81%E7%A8%8B.png?raw=true)

以上是传统IO操作执行步骤，有 4 次上下文的切换和 4 次拷贝。

DMA拷贝：直接内存存取，代替CPU去执行一部分拷贝的工作。

零拷贝一般有 mmap 和 sendFile 两种。

1. mmap：是一种内存映射技术，mmap 相比于传统的 IO 来说，其实就是少了 1 次 CPU 拷贝而已。

   传统 IO 里面从内核缓冲区到用户缓冲区有一次 CPU 拷贝，从用户缓冲区到 Socket 缓冲区又有一次 CPU 拷贝。mmap 则一步到位，直接基于 CPU 将内核缓冲区的数据拷贝到了 Socket 缓冲区。

   之所以能够减少一次拷贝，就是因为 mmap 直接将**磁盘文件数据映射到内核缓冲区**，适合小数据量读写，这个映射的过程是基于 DMA 拷贝的，**同时用户缓冲区是跟内核缓冲区共享一块映射数据的**，**建立共享映射**之后，就不需要从内核缓冲区拷贝到用户缓冲区了。

   ![mmap](https://github.com/Eleven-is-cool/img-folder/blob/master/mmap.png?raw=true)

2. sendFile：

   sendfile 是将读到内核空间的数据，转到 socket buffer，进行网络发送，适合大文件传输，只需要 2 次上下文切换（用户态 -> 内核态 -> 用户态）和 2 次拷贝（磁盘文件 DMA 拷贝到内核缓冲区，内核缓冲区 DMA 拷贝到协议引擎）。

   **所有的数据都是通过 DMA 来进行传输的。**

   - 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
   - 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；

   ![sendFile](https://github.com/Eleven-is-cool/img-folder/blob/master/sendFile.png?raw=true)

**在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术**。

[详细请见](https://mp.weixin.qq.com/s/P0IP6c_qFhuebwdwD8HM7w)

# PageCache

内核缓冲区实际上是**磁盘高速缓存（PageCache）。**

**PageCache 来缓存最近被访问的数据**，当空间不足时淘汰最久未被访问的缓存。

读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。

读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，**PageCache 使用了「预读功能」**。

综上，PageCache 的优点主要是两个：

- **缓存最近被访问的数据；**
- **预读功能；**

# `fork`

## 返回结果

fork函数被父进程**调用一次**，但是却**返回两次**；一次是返回到**父进程**，一次是返回到**新创建的子进程**。 

1. 在父进程中，fork返回新创建子进程的进程ID；
2. 在子进程中，fork返回0；
3. 如果出现错误，fork返回一个负值；

## fork的常规用法 

1. 一个父进程希望复制自己，**使得子进程同时执行不同的代码段**，例如：父进程等待客户端请求，生成一个子进程来等待请求处理。 

2. 一个进程要执行一个不同的程序。

## 其他

1. 当父进程或者子进程单独改变时，不会影响到彼此。
2. 在fork()的调用处，整个父进程空间会原模原样地复制到子进程中，包括指令，变量值，程序调用栈，环境变量，缓冲区，等等。
3. [**题目：请问下面的程序一共输出多少个“-”？**](https://coolshell.cn/articles/7965.html/comment-page-4#comments)

# 块设备和字符设备

块设备，就是以一块一块的数据存取的设备，磁盘、内存都是块设备。

字符设备是一次存取一个字符的设备，字符设备如键盘和串口。

**块设备一般都有缓存，而字符设备一般都没有缓存**。

# 守护进程

守护进程（Daemon）是运行在后台的一种特殊进程。它**独立于控制终端**并且周期性地执行某种任务或等待处理某些发生的事件。

守护进程是一种很有用的进程。Linux的大多数服务器就是用守护进程实现的。比如，Internet服务器inetd，Web服务器httpd等。同时，守护进程完成许多系统任务。比如，作业规划进程crond，打印进程lpd等。

[守护进程的创建](https://blog.csdn.net/DLUTBruceZhang/article/details/16349675)

# 僵尸进程和孤儿进程

**孤儿进程：**一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

**僵尸进程：**一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用 wait 或 waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。













